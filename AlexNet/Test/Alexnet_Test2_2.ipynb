{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_3yqBvTXA-X",
        "outputId": "aed2f711-6b6f-4955-b55d-5e0bb7431b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  6 15:45:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn  # 신경망 모듈, 구축 및 훈련에 사용\n",
        "from torch.utils.data.dataset import Dataset # 사용자 정의 데이터 셋을 만들어 딥러닝을 할 수 있게 함\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms # 이미지 전처리에 필요한 transform 사용\n",
        "from torch.utils.data import DataLoader # 데이터 관리에 필요한 dataloader\n",
        "import torch.nn.functional as F # loss or cost gradient와 같은 여러 함수를 사용할 수 있음\n",
        "from sklearn.metrics import f1_score, confusion_matrix # f1 score와 행렬을 계산 -> 모델의 성능 평가\n",
        "import numpy as np # numpy 사용\n",
        "import matplotlib.pyplot as plt #시각화를 위한 차트 사용\n",
        "from torch.cuda import is_available\n",
        "from torchvision.datasets import CIFAR10"
      ],
      "metadata": {
        "id": "dSbhQrqFXGjd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if is_available() else 'cpu'\n",
        "lr = 1e-4\n",
        "batch_size=32\n",
        "epoch = 10"
      ],
      "metadata": {
        "id": "BhBkR6tEXRLw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data=CIFAR10(root='.',train=True,transform=transforms.ToTensor(),download=True)\n",
        "\n",
        "meanRGB=[np.mean(x.numpy(),axis=(1,2)) for x,_ in all_data]\n",
        "stdRGB=[np.std(x.numpy(),axis=(1,2)) for x,_ in all_data]\n",
        "\n",
        "meanR = np.mean([m[0] for m in meanRGB])\n",
        "meanG = np.mean([m[1] for m in meanRGB])\n",
        "meanB = np.mean([m[2] for m in meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in stdRGB])\n",
        "stdG = np.mean([s[1] for s in stdRGB])\n",
        "stdB = np.mean([s[2] for s in stdRGB])\n",
        "\n",
        "print('Mean:',meanR, meanG, meanB)\n",
        "print('Std:',stdR, stdG, stdB)\n",
        "mean = [meanR, meanG, meanB]\n",
        "std = [stdR, stdG, stdB]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suzl2kffFUdC",
        "outputId": "ebc987ad-8b3e-4468-95b5-59d2afc82da0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Mean: 0.49139965 0.48215845 0.4465309\n",
            "Std: 0.20220213 0.19931543 0.20086348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.CenterCrop(227),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(227, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "    # transforms.RandomGrayscale(p=0.2),\n",
        "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),                        # 텐서로 변환\n",
        "    transforms.Normalize(mean, std)])"
      ],
      "metadata": {
        "id": "OmJizqRVXPt9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB2P2o7MXUcO",
        "outputId": "fcfad52b-dd67-4538-a0ec-38d59519eb6c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels, 96, kernel_size=11, stride=4), # conv1\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.LocalResponseNorm(2),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2), # conv2\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.LocalResponseNorm(2),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1), # conv3\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1), # conv4\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1), # conv5\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6,6))\n",
        "\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(6*6*256, 4096), # fc1\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(4096, 4096), # fc2\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(4096, num_classes) # fc3\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aicy-4OxXVw9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(in_channels = 3, num_classes=10).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "atR0YIqYXYvp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_loader, optimizer, Epoch):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total_samples = len(train_loader.dataset)\n",
        "\n",
        "    with tqdm(total=len(train_loader), unit=\"batch\") as tepoch:\n",
        "        tepoch.set_description(f\"Epoch {Epoch+1}\")\n",
        "        for batch_idx, (image, label) in enumerate(train_loader):\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(image)\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "            tepoch.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "            tepoch.update(1)\n",
        "\n",
        "    train_loss = np.mean(losses)\n",
        "    accuracy = 100. * correct / total_samples\n",
        "\n",
        "    return train_loss, accuracy\n"
      ],
      "metadata": {
        "id": "xkn4txvLYYKz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "            output = model(image)\n",
        "            loss = criterion(output, label)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "\n",
        "    test_loss = np.mean(losses)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "E-q-upjEYZXy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for Epoch in range(11):\n",
        "    train_loss, train_accuracy = train(model, trainloader, optimizer, Epoch)\n",
        "    test_loss, test_accuracy = evaluate(model, testloader)\n",
        "\n",
        "    # 각 에폭별로 훈련 손실과 정확도, 테스트 손실과 정확도를 저장\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    print(f\"\\n[EPOCH: {Epoch+1}]\\tTrain Loss: {train_loss:.4f}\\tTrain Accuracy: {train_accuracy} %\")\n",
        "    print(f\"[EPOCH: {Epoch+1}]\\tTest Loss: {test_loss:.4f}\\tTest Accuracy: {test_accuracy} % \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Q5BtoFYa0e",
        "outputId": "43c6044f-2059-437e-98b0-a346b65b6e87"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1563/1563 [03:05<00:00,  8.43batch/s, loss=1.2875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 1]\tTrain Loss: 1.5157\tTrain Accuracy: 43.978 %\n",
            "[EPOCH: 1]\tTest Loss: 1.0930\tTest Accuracy: 61.27 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 1563/1563 [03:13<00:00,  8.09batch/s, loss=1.4942]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 2]\tTrain Loss: 0.9934\tTrain Accuracy: 65.136 %\n",
            "[EPOCH: 2]\tTest Loss: 0.8307\tTest Accuracy: 71.01 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 1563/1563 [03:19<00:00,  7.84batch/s, loss=0.4915]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 3]\tTrain Loss: 0.7802\tTrain Accuracy: 72.942 %\n",
            "[EPOCH: 3]\tTest Loss: 0.7622\tTest Accuracy: 73.62 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 1563/1563 [03:19<00:00,  7.83batch/s, loss=1.1889]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 4]\tTrain Loss: 0.6580\tTrain Accuracy: 77.35 %\n",
            "[EPOCH: 4]\tTest Loss: 0.6736\tTest Accuracy: 76.89 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 1563/1563 [03:20<00:00,  7.79batch/s, loss=0.2106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 5]\tTrain Loss: 0.5654\tTrain Accuracy: 80.416 %\n",
            "[EPOCH: 5]\tTest Loss: 0.6216\tTest Accuracy: 78.88 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 1563/1563 [03:21<00:00,  7.77batch/s, loss=0.4117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 6]\tTrain Loss: 0.4976\tTrain Accuracy: 82.672 %\n",
            "[EPOCH: 6]\tTest Loss: 0.5883\tTest Accuracy: 80.33 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 1563/1563 [03:25<00:00,  7.60batch/s, loss=0.6953]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 7]\tTrain Loss: 0.4404\tTrain Accuracy: 84.904 %\n",
            "[EPOCH: 7]\tTest Loss: 0.5558\tTest Accuracy: 81.62 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 1563/1563 [03:25<00:00,  7.59batch/s, loss=0.5658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 8]\tTrain Loss: 0.3855\tTrain Accuracy: 86.67 %\n",
            "[EPOCH: 8]\tTest Loss: 0.5322\tTest Accuracy: 82.1 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 1563/1563 [03:25<00:00,  7.59batch/s, loss=0.6265]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 9]\tTrain Loss: 0.3486\tTrain Accuracy: 87.894 %\n",
            "[EPOCH: 9]\tTest Loss: 0.5393\tTest Accuracy: 82.35 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 1563/1563 [03:25<00:00,  7.61batch/s, loss=1.0098]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 10]\tTrain Loss: 0.3084\tTrain Accuracy: 89.37 %\n",
            "[EPOCH: 10]\tTest Loss: 0.5300\tTest Accuracy: 82.82 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 1563/1563 [03:24<00:00,  7.64batch/s, loss=0.1719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 11]\tTrain Loss: 0.2750\tTrain Accuracy: 90.634 %\n",
            "[EPOCH: 11]\tTest Loss: 0.5142\tTest Accuracy: 83.84 % \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "epochs = range(1, 12)\n",
        "# 첫 번째 그래프\n",
        "plt.subplot(1, 2, 1)  # 1행 2열 중 첫 번째 그래프\n",
        "plt.plot(epochs, train_losses, label='Train Loss',marker='^')\n",
        "plt.plot(epochs, test_losses, label='Test Loss',marker='^')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# 두 번째 그래프\n",
        "plt.subplot(1, 2, 2)  # 1행 2열 중 두 번째 그래프\n",
        "plt.plot(epochs, train_accuracies, label='Train Accuracy',marker='^')\n",
        "plt.plot(epochs, test_accuracies, label='Test Accuracy',marker='^')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gPTutKqEgrex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFjMOz5IXHyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}